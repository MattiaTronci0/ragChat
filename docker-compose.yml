version: '3.8'

services:
  frontend:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - VITE_ANYTHINGLLM_URL=${VITE_ANYTHINGLLM_URL:-http://localhost:3001/api/v1}
        - VITE_ANYTHINGLLM_API_KEY=${ANYTHINGLLM_API_KEY}
        - VITE_ANYTHINGLLM_WORKSPACE=${ANYTHINGLLM_WORKSPACE}
    environment:
      - NODE_ENV=production
    depends_on:
      - api-proxy
    networks:
      - ragchat-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  api-proxy:
    build:
      context: ./api-proxy
      dockerfile: Dockerfile
    environment:
      - NODE_ENV=production
      - PORT=3002
      - ANYTHINGLLM_BASE_URL=http://anythingllm:3001
      - ANYTHINGLLM_API_KEY=ETVXYEN-K9CMYY4-K3X6WRJ-XSS8SXQ
      - ANYTHINGLLM_WORKSPACE=${ANYTHINGLLM_WORKSPACE}
      - FRONTEND_URL=http://localhost
    depends_on:
      anythingllm:
        condition: service_healthy
    networks:
      - ragchat-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    restart: unless-stopped

  anythingllm:
    image: mintplexlabs/anythingllm:latest
    ports:
      - "3001:3001"
    volumes:
      - anythingllm-storage:/app/server/storage
    environment:
      - STORAGE_DIR=/app/server/storage
      - JWT_SECRET=${JWT_SECRET}
      - PASSWORDMINCHAR=8
      - LLM_PROVIDER=${LLM_PROVIDER:-ollama}
      - EMBEDDING_ENGINE=${EMBEDDING_ENGINE:-ollama}
      - VECTOR_DB=lancedb
    networks:
      - ragchat-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/api/system/ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "8080:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/ssl/certs
    depends_on:
      frontend:
        condition: service_healthy
      api-proxy:
        condition: service_healthy
    networks:
      - ragchat-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped

volumes:
  anythingllm-storage:
    driver: local

networks:
  ragchat-network:
    driver: bridge